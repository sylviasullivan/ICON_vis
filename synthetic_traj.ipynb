{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, time\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import NamedTemporaryFile, TemporaryDirectory # Creating temporary Files/Dirs\n",
    "import dask # Distributed data libary\n",
    "from dask_jobqueue import SLURMCluster # Setting up distributed memories via slurm\n",
    "from distributed import Client, progress, wait # Libaray to orchestrate distributed resources"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import line_profiler\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some user specific variables\n",
    "account_name = 'bb1018'\n",
    "partition = 'compute'\n",
    "job_name = 'extractSim' # Job name that is submitted via sbatch\n",
    "memory = '24GiB' # 64GiB, Max memory per node that is going to be used - this depends on the partition\n",
    "cores = 48 # Max number of cores per that are reserved - also partition dependent\n",
    "walltime = '07:00:00' #'12:00:00' # Walltime - also partition dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch_dir = '/scratch/b/b380873/' # Define the users scratch dir\n",
    "# Create a temp directory where the output of distributed cluster will be written to, after this notebook\n",
    "# is closed the temp directory will be closed\n",
    "dask_scratch_dir = TemporaryDirectory(dir=scratch_dir, prefix=job_name)\n",
    "cluster = SLURMCluster(memory=memory,\n",
    "                       cores=cores,\n",
    "                       project=account_name,\n",
    "                       walltime=walltime,\n",
    "                       queue=partition,\n",
    "                       name=job_name,\n",
    "                       processes=8,\n",
    "                       scheduler_options={'dashboard_address': ':12435'},\n",
    "                       local_directory=dask_scratch_dir.name,\n",
    "                       job_extra=[f'-J {job_name}', \n",
    "                                  f'-D {dask_scratch_dir.name}',\n",
    "                                  f'--begin=now',\n",
    "                                  f'--output={dask_scratch_dir.name}/LOG_cluster.%j.o',\n",
    "                                  f'--output={dask_scratch_dir.name}/LOG_cluster.%j.o'\n",
    "                                 ],\n",
    "                       interface='ib0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env bash\n",
      "\n",
      "#SBATCH -J dask-worker\n",
      "#SBATCH -p compute\n",
      "#SBATCH -A bb1018\n",
      "#SBATCH -n 1\n",
      "#SBATCH --cpus-per-task=48\n",
      "#SBATCH --mem=24G\n",
      "#SBATCH -t 07:00:00\n",
      "#SBATCH -J extractSim\n",
      "#SBATCH -D /scratch/b/b380873/extractSimtnq2g90a\n",
      "#SBATCH --begin=now\n",
      "#SBATCH --output=/scratch/b/b380873/extractSimtnq2g90a/LOG_cluster.%j.o\n",
      "#SBATCH --output=/scratch/b/b380873/extractSimtnq2g90a/LOG_cluster.%j.o\n",
      "\n",
      "JOB_ID=${SLURM_JOB_ID%;*}\n",
      "\n",
      "/pf/b/b380459/conda-envs/Nawdex-Hackathon/bin/python3 -m distributed.cli.dask_worker tcp://10.50.40.21:45187 --nthreads 6 --nprocs 8 --memory-limit 3.22GB --name name --nanny --death-timeout 60 --local-directory /scratch/b/b380873/extractSimtnq2g90a --interface ib0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cluster.job_script())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fdf989e62e2425cb37c44e1216b1ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>extractSim</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n    .dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster.scale(jobs=1)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.50.40.21:45187</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.50.40.21:8787/status' target='_blank'>http://10.50.40.21:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.50.40.21:45187' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask_client = Client(cluster)\n",
    "dask_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which simulation and variable do you want to look at? How many synthetic trajectories to generate?\n",
    "global sim_acronym\n",
    "global n\n",
    "\n",
    "# Over which lat-lon and altitude interval should we extract data?\n",
    "global ll_interval\n",
    "global alt_interval\n",
    "\n",
    "sim_acronym = '0V2M0A0R'\n",
    "n = 10\n",
    "ll_interval = 0.75\n",
    "alt_interval = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input a np.datetime64 and round it to the nearest 10 minutes.\n",
    "def timeround10(dt):\n",
    "    dt_not_np = pd.to_datetime(dt)\n",
    "    b = round(dt_not_np.minute,-1)\n",
    "    if b == 60:\n",
    "        return_time = datetime.datetime(2017, 8, 8, dt_not_np.hour + 1, 0)\n",
    "    else:\n",
    "        return_time = datetime.datetime(2017, 8, 8, dt_not_np.hour, int(b))\n",
    "    return return_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract <n> random indices along all dimensions of the variable <var>\n",
    "# I feel that there is a more Pythonic way of doing this but it works for now\n",
    "def randIndx(var):\n",
    "    dim_rand = np.empty((n, 4), dtype='int')\n",
    "    t_size, alt_size, lat_size, lon_size = var.shape\n",
    "    dim_rand[:, 0] = np.random.randint(low=0, high=t_size, size=n)\n",
    "    dim_rand[:, 1] = np.random.randint(low=0, high=alt_size, size=n)\n",
    "    dim_rand[:, 2] = np.random.randint(low=0, high=lat_size, size=n)\n",
    "    dim_rand[:, 3] = np.random.randint(low=0, high=lon_size, size=n)\n",
    "    return dim_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the existing syn_traj Dataset along with time, pressure, lat, and lon from the flight track\n",
    "def extractSim(syn_traj, flight_time, flight_pressure, flight_lat, flight_lon):\n",
    "    # Translate the variable key to its corresponding file\n",
    "    sim_dir = '/work/bb1018/b380873/model_output/ICON/'\n",
    "    var_ICON = xr.open_dataset(sim_dir + 'ICON_3D_F10MIN_icon_tropic_0V2M0A0R_PL2.nc')\n",
    "\n",
    "    # Find the nearest whole 10-min time.\n",
    "    flight_time_approx = timeround10(flight_time.values)\n",
    "\n",
    "    # Construct the time window to extract.\n",
    "    early_time = flight_time_approx - datetime.timedelta(minutes=30)\n",
    "    late_time = flight_time_approx + datetime.timedelta(minutes=30)\n",
    "\n",
    "    # Find the indices for levels above and below the closest match.\n",
    "    basedir = '/work/bb1018/b380873/tropic_vis/remapping/'\n",
    "    sim_pressures = np.loadtxt(basedir + 'PMEAN_48-72.txt')\n",
    "    i = np.argmin(np.abs(flight_pressure - sim_pressures))\n",
    "    if i < 1 or i > 117:\n",
    "        raise Exception('Flight pressure outside of simulation range.')\n",
    "    var_ICON = var_ICON.isel( plev=slice(i-alt_interval, i+alt_interval+1) )\n",
    "\n",
    "    # Define the lat-lon interval to extract\n",
    "    var_ICON = var_ICON.sel( time=slice(early_time, late_time),\n",
    "                             lat=slice(flight_lat-ll_interval, flight_lat+ll_interval),\n",
    "                             lon=slice(flight_lon-ll_interval, flight_lon+ll_interval) )\n",
    "\n",
    "    dim_rand = randIndx(var_ICON['qv'])\n",
    "    for k, dims in enumerate(dim_rand):\n",
    "        for v in syn_traj.variables:\n",
    "            if v != 'ntraj' and v != 'time':\n",
    "                syn_traj[v].loc[dict(ntraj=k+1, time=flight_time)] = var_ICON[v].isel(time=dims[0], plev=dims[1], lat=dims[2], lon=dims[3])\n",
    "                    \n",
    "    return syn_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the observational data\n",
    "basedir = '/work/bb1018/b380873/tropic_vis/obs/'\n",
    "fi = basedir + 'stratoclim2017.geophysika.0808_1.filtered_per_sec.nc'\n",
    "Stratoclim = xr.open_dataset(fi)\n",
    "flight_times = Stratoclim['time']\n",
    "\n",
    "# <j> is the first iteration for which there are ICON high-resolution values available.\n",
    "j = 1942 # 1342\n",
    "tt = flight_times.shape[0] - j\n",
    "\n",
    "# Load the ICON values\n",
    "ICON = xr.open_dataset('/work/bb1018/b380873/model_output/ICON/ICON_3D_F10MIN_icon_tropic_0V2M0A0R_PL2.nc')\n",
    "\n",
    "# Initiate the synthetic trajectory Dataset\n",
    "syn_traj = xr.Dataset( data_vars=dict(\n",
    "                            temp=( [\"time\", \"ntraj\"], np.empty([tt, n]) ),\n",
    "                            omega=( [\"time\", \"ntraj\"], np.empty([tt, n]) ),\n",
    "                            air_pressure=( [\"time\", \"ntraj\"], np.empty([tt, n]) ),\n",
    "                            qv=( [\"time\", \"ntraj\"], np.empty([tt, n]) ),\n",
    "                            qc=( [\"time\", \"ntraj\"], np.empty([tt, n]) ),\n",
    "                            qi=( [\"time\", \"ntraj\"], np.empty([tt, n]) ),\n",
    "                            qs=( [\"time\", \"ntraj\"], np.empty([tt, n]) ),\n",
    "                            qg=( [\"time\", \"ntraj\"], np.empty([tt, n]) ),\n",
    "                        ),\n",
    "                       coords=dict(\n",
    "                           time=flight_times[j:], ntraj=np.arange(1, n+1))\n",
    "                     )\n",
    "\n",
    "# Set the variable attributes as in the standard ICON output file.\n",
    "for v in syn_traj.variables:\n",
    "    if v != 'time' and v!= 'ntraj':\n",
    "        syn_traj[v].attrs[\"long_name\"] = ICON[v].long_name\n",
    "        syn_traj[v].attrs[\"units\"] = ICON[v].units\n",
    "        syn_traj[v].attrs[\"standard_name\"] = ICON[v].standard_name\n",
    "\n",
    "syn_traj['ntraj'].attrs[\"long_name\"] = 'Trajectory ID'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "for flight_iter, flight_time in enumerate(flight_times[j:j+50]):\n",
    "    if flight_iter%500 == 0:\n",
    "        print(flight_iter)\n",
    "    flight_pressure = Stratoclim['BEST:PRESS'].sel(time=flight_time).values*100 # [Pa]\n",
    "    flight_lat = Stratoclim['BEST:LAT'].sel(time=flight_time).values\n",
    "    flight_lon = Stratoclim['BEST:LON'].sel(time=flight_time).values\n",
    "\n",
    "    # Based on the flight values, load the relevant chunk of simulations\n",
    "    syn_traj = extractSim(syn_traj, flight_time, flight_pressure, flight_lat, flight_lon)\n",
    "\n",
    "syn_traj.to_netcdf(path='/work/bb1018/b380873/model_output/ICON/ICON_syn_traj2.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "CPU times: user 37.6 s, sys: 664 ms, total: 38.3 s\n",
      "Wall time: 45.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Delayed('to_netcdf-b797c291-3591-4972-b338-f208ce725e32')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for flight_iter, flight_time in enumerate(flight_times[j:]):\n",
    "    if flight_iter%500 == 0:\n",
    "        print(flight_iter)\n",
    "    flight_pressure = Stratoclim['BEST:PRESS'].sel(time=flight_time).values*100 # [Pa]\n",
    "    flight_lat = Stratoclim['BEST:LAT'].sel(time=flight_time).values\n",
    "    flight_lon = Stratoclim['BEST:LON'].sel(time=flight_time).values\n",
    "\n",
    "    # Based on the flight values, load the relevant chunk of simulations\n",
    "    syn_traj = dask.delayed(extractSim)(syn_traj, flight_time, flight_pressure, flight_lat, flight_lon)\n",
    "\n",
    "syn_traj.to_netcdf(path='/work/bb1018/b380873/model_output/ICON/ICON_syn_traj2.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pf/b/b380459/conda-envs/Nawdex-Hackathon/lib/python3.8/site-packages/distributed/worker.py:3373: UserWarning: Large object of size 7.02 MB detected in task graph: \n",
      "  (<xarray.Dataset>\n",
      "Dimensions:       (ntraj: 10, ti ... dtype=float32))\n",
      "Consider scattering large objects ahead of time\n",
      "with client.scatter to reduce scheduler burden and \n",
      "keep data on workers\n",
      "\n",
      "    future = client.submit(func, big_data)    # bad\n",
      "\n",
      "    big_future = client.scatter(big_data)     # good\n",
      "    future = client.submit(func, big_future)  # good\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "syn_traj.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nawdex-hackathon",
   "language": "python",
   "name": "nawdex-hackathon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
